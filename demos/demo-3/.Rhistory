# data wrangling
library(dplyr)
library(magrittr)
library(stringr)
library(stringi)
library(readr)
# machine learning and advanced analytics
library(DMwR)
library(caret)
library(caretEnsemble)
library(pROC)
# natural language processing
# library(languageR)
library(tm)
library(jiebaR)
# tools
library(httr)
library(XML)
library(jsonlite)
# data visualization
library(scales)
library(ggplot2)
library(ggmap)
# data
data(iris)
DATA1 <- "https://raw.githubusercontent.com/Microsoft/acceleratoRs/master/EmployeeAttritionPrediction/Data/DataSet1.csv"
DATA2 <- "https://raw.githubusercontent.com/Microsoft/acceleratoRs/master/EmployeeAttritionPrediction/Data/DataSet2.csv"
df1 <- read_csv(DATA1)
df2 <- read_csv(DATA2)
control <- trainControl(method="repeatedcv", number=1, repeats=1)
# train the model
model <- train(dplyr::select(df1, -Attrition),
df1$Attrition,
data=df1,
method="rf",
preProcess="scale",
trControl=control)
head(df1)
control <- trainControl(method="repeatedcv", number=3, repeats=1)
# train the model
model <- train(dplyr::select(df1, -Attrition),
df1$Attrition,
data=df1,
method="rf",
preProcess="scale",
trControl=control)
# get predictors that has no variation.
pred_no_var <- names(df1[, nearZeroVar(df)]) %T>% print()
# data wrangling
library(dplyr)
library(magrittr)
library(stringr)
library(stringi)
library(readr)
# machine learning and advanced analytics
library(DMwR)
library(caret)
library(caretEnsemble)
library(pROC)
# natural language processing
# library(languageR)
library(tm)
library(jiebaR)
# tools
library(httr)
library(XML)
library(jsonlite)
# data visualization
library(scales)
library(ggplot2)
library(ggmap)
# data
data(iris)
DATA1 <- "https://raw.githubusercontent.com/Microsoft/acceleratoRs/master/EmployeeAttritionPrediction/Data/DataSet1.csv"
DATA2 <- "https://raw.githubusercontent.com/Microsoft/acceleratoRs/master/EmployeeAttritionPrediction/Data/DataSet2.csv"
df1 <- read_csv(DATA1)
df2 <- read_csv(DATA2)
dim(df1)
dim(df2)
head(df2$Feedback, 3)
# get predictors that has no variation.
pred_no_var <- names(df1[, nearZeroVar(df)]) %T>% print()
# get predictors that has no variation.
pred_no_var <- names(df1[, nearZeroVar(df1)]) %T>% print()
# get predictors that has no variation.
pred_no_var <- names(df1[, nearZeroVar(df1)]) %T>% print()
# remove the zero variation predictor columns.
df1 %<>% select(-one_of(pred_no_var))
# convert certain interger variable to factor variable.
int_2_ftr_vars <- c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "NumCompaniesWorked", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel")
df1[, int_2_ftr_vars] <- lapply((df1[, int_2_ftr_vars]), as.factor)
# convert remaining integer variables to be numeric.
df1 %<>% mutate_if(is.integer, as.numeric)
df1 %<>% mutate_if(is.character, as.factor)
glimpse(df1)
control <- trainControl(method="repeatedcv", number=3, repeats=1)
# train the model
model <- train(dplyr::select(df1, -Attrition),
df1$Attrition,
data=df1,
method="rf",
preProcess="scale",
trControl=control)
# estimate variable importance
imp <- varImp(model, scale=FALSE)
# select the top-ranking variables.
imp_list <- rownames(imp$importance)[order(imp$importance$Overall, decreasing=TRUE)]
# drop the low ranking variables. Here the last 3 variables are dropped.
top_var <-
imp_list[1:(ncol(df) - 3)] %>%
as.character()
top_var
# select the top-ranking variables.
imp_list <- rownames(imp$importance)[order(imp$importance$Overall, decreasing=TRUE)]
# drop the low ranking variables. Here the last 3 variables are dropped.
top_var <-
imp_list[1:(ncol(df1) - 3)] %>%
as.character()
top_var
train_index <-
createDataPartition(df1$Attrition,
times=1,
p=.7) %>%
unlist()
df1_train <- df1[train_index, ]
df1_test <- df1[-train_index, ]
table(df1_train$Attrition)
df1_train %<>% as.data.frame()
df1_train <- SMOTE(Attrition ~ .,
df1_train,
perc.over=300,
perc.under=150)
table(df1_train$Attrition)
# initialize training control.
tc <- trainControl(method="boot",
number=3,
repeats=3,
search="grid",
classProbs=TRUE,
savePredictions="final",
summaryFunction=twoClassSummary)
# SVM model.
time_svm <- system.time(
model_svm <- train(Attrition ~ .,
df1_train,
method="svmRadial",
trainControl=tc)
)
# random forest model
time_rf <- system.time(
model_rf <- train(Attrition ~ .,
df1_train,
method="rf",
trainControl=tc)
)
# xgboost model.
time_xgb <- system.time(
model_xgb <- train(Attrition ~ .,
df1_train,
method="xgbLinear",
trainControl=tc)
)
# ensemble of the three models.
time_ensemble <- system.time(
model_list <- caretList(Attrition ~ .,
data=df1_train,
trControl=tc,
methodList=c("svmRadial", "rf", "xgbLinear"))
)
# stack of models. Use glm for meta model.
model_stack <- caretStack(
model_list,
metric="ROC",
method="glm",
trControl=tc
)
models <- list(model_svm, model_rf, model_xgb, model_stack)
predictions <-lapply(models,
predict,
newdata=select(df_test, -Attrition))
models <- list(model_svm, model_rf, model_xgb, model_stack)
predictions <-lapply(models,
predict,
newdata=select(df1_test, -Attrition))
# confusion matrix evaluation results.
cm_metrics <- lapply(predictions,
confusionMatrix,
reference=df_test$Attrition,
positive="Yes")
# confusion matrix evaluation results.
cm_metrics <- lapply(predictions,
confusionMatrix,
reference=df1_test$Attrition,
positive="Yes")
# accuracy
acc_metrics <-
lapply(cm_metrics, `[[`, "overall") %>%
lapply(`[`, 1) %>%
unlist()
# recall
rec_metrics <-
lapply(cm_metrics, `[[`, "byClass") %>%
lapply(`[`, 1) %>%
unlist()
# precision
pre_metrics <-
lapply(cm_metrics, `[[`, "byClass") %>%
lapply(`[`, 3) %>%
unlist()
algo_list <- c("SVM RBF", "Random Forest", "Xgboost", "Stacking")
time_consumption <- c(time_svm[3], time_rf[3], time_xgb[3], time_ensemble[3])
df_comp <-
data.frame(Models=algo_list,
Accuracy=acc_metrics,
Recall=rec_metrics,
Precision=pre_metrics,
Time=time_consumption) %T>%
{head(.) %>% print()}
save(models, "../OneDrive - Microsoft/work/projects/r_interface/Azure-R-Interface/demos/demo-3/models.RData")
save(models, file = "../OneDrive - Microsoft/work/projects/r_interface/Azure-R-Interface/demos/demo-3/models.RData")
?save.image
save.image(file="models.RData", list=c("model", "model_list", "model_rf", "model_svm", "model_stack", "model_xgb"))
save(model, model_list, model_rf, model_svm, model_stack, model_xgb, file="models.RData")
save(model, models, model_list, model_rf, model_svm, model_stack, model_xgb, file="models.RData")
# getting the data.
head(df2$Feedback, 10)
# create a corpus based upon the text data.
corp_text <- Corpus(VectorSource(df2$Feedback))
# the transformation functions can be checked with
getTransformations()
# transformation on the corpus.
corp_text %<>%
tm_map(removeNumbers) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
dtm_txt_tf <-
DocumentTermMatrix(corp_text, control=list(wordLengths=c(1, Inf), weighting=weightTf))
# remove sparse terms.
dtm_txt <-
removeSparseTerms(dtm_txt_tf, 0.99)
df_txt <-
inspect(dtm_txt) %>%
as.data.frame()
head(df_txt, 20)
# form the data set
df_txt %<>% cbind(Attrition=df$Attrition)
# form the data set
df_txt %<>% cbind(Attrition=df1$Attrition)
# form the data set
df_txt %<>% cbind(Attrition=df2$Attrition)
# split data set into training and testing set.
train_index <-
createDataPartition(df_txt$Attrition,
times=1,
p=.7) %>%
unlist()
df_txt_train <- df_txt[train_index, ]
df_txt_test <- df_txt[-train_index, ]
# model building
model_sent <- train(Attrition ~ .,
df_txt_train,
method="svmRadial",
trainControl=tc)
save(model, models, model_list, model_rf, model_svm, model_stack, model_xgb, model_sent, file="models.RData")
setwd("../OneDrive - Microsoft/work/projects/r_interface/Azure-R-Interface/demos/demo-3/")
list.files(".")
?svm
model_iris <- rpart(formula=Species ~ Sepal.Length + Sepal.Width,
data=iris)
fancyRpartPlot(model_iris)
library(rattle)
fancyRpartPlot(model_iris)
save(model, models, model_list, model_rf, model_svm, model_stack, model_xgb, model_sent, model_iris, file="./models.RData")
getwd()
session.info()
session.info()
?fancyRpartPlot
sessionInfo()
x <- sessionInfo()
x$running
x$R.version
x$otherPkgs
sessionInfo()
?sessionInfo
sessionInfo(locale=FALSE)
sessionInfo(package=NULL)
print(sessionInfo(), locale=FALSE)
x <- sessionInfo()
x$otherPkgs$rattle$Package
print(sessionInfo(), locale=FALSE)
imp
qplot(imp)
plot(imp)
save(model, models, model_list, model_rf, model_svm, model_stack, model_xgb, model_sent, time_svm, time_rf, time_xgb, time_ensemble, file="models.RData")
save(model, models, model_list, model_rf, model_svm, model_stack, model_xgb, model_sent, model_iris, time_svm, time_rf, time_xgb, time_ensemble, file="models.RData")
